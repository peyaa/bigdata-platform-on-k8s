<?xml version="1.0"?>
<configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///opt/hdfs/namenode/{node_dir}</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///opt/hdfs/datanode/{node_dir}</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
      <name>dfs.datanode.address</name>
      <value>0.0.0.0:{dfs_datanode_address_port}</value>
    </property>
    <property>
      <name>dfs.datanode.http.address</name>
      <value>0.0.0.0:{dfs_datanode_http_address_port}</value>
    </property>
    <property>
      <name>dfs.datanode.https.address</name>
      <value>0.0.0.0:{dfs_datanode_https_address_port}</value>
    </property>
    <property>
      <name>dfs.datanode.ipc.address</name>
      <value>0.0.0.0:{dfs_datanode_ipc_address_port}</value>
    </property>
    <property>
      <name>dfs.journalnode.rpc-address</name>
      <value>0.0.0.0:{dfs_journalnode_rpc_address_port}</value>
    </property>
    <property>
      <name>dfs.journalnode.http-address</name>
      <value>0.0.0.0:{dfs_journalnode_http_address_port}</value>
    </property>
    <property>
      <name>dfs.journalnode.https-address</name>
      <value>0.0.0.0:{dfs_journalnode_https_address_port}</value>
    </property>
    <property>
        <name>dfs.nameservices</name>
        <value>{hadoop_ha_cluster_name}</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.{hadoop_ha_cluster_name}</name>
        <value>nn1,nn2</value>
    </property>
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://{journal_node_url}/{hadoop_ha_cluster_name}</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.{hadoop_ha_cluster_name}.nn1</name>
        <value>{hadoop_master_node_host_name}:{dfs_namenode_rpc_address_nn1_port}</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.{hadoop_ha_cluster_name}.nn2</name>
        <value>{hadoop_master_node_host_name}-standby:{dfs_namenode_rpc_address_nn2_port}</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.{hadoop_ha_cluster_name}.nn1</name>
        <value>{hadoop_master_node_host_name}:{dfs_namenode_http_address_nn1_port}</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.{hadoop_ha_cluster_name}.nn2</name>
        <value>{hadoop_master_node_host_name}-standby:{dfs_namenode_http_address_nn2_port}</value>
    </property>
    <property>
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.ha.automatic-failover.enabled.{hadoop_ha_cluster_name}</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.{hadoop_ha_cluster_name}</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
    </property>
    <property>
        <name>dfs.namenode.avoid.read.stale.datanode</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.namenode.avoid.write.stale.datanode</name>
        <value>true</value>
    </property>
    <property>
      <name>dfs.namenode.stale.datanode.interval</name>
      <value>30000</value>
    </property>
    <property>
      <name>dfs.namenode.heartbeat.recheck-interval</name>
      <value>5000</value>
    </property>
    <property>
      <name>dfs.journalnode.edits.dir</name>
      <value>/opt/hdfs/journalnode/{node_dir}</value>
    </property>
</configuration>